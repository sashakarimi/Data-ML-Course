{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# - Nothing for the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# OS-independent way to navigate the file system\n",
    "# Data directory is one directory up in relation to directory of this notebook\n",
    "curr_dir = os.path.normpath(os.getcwd())\n",
    "if '/Untracked/Notebooks' in curr_dir:\n",
    "    data_dir = curr_dir.replace('/Untracked/Notebooks', '/Data')\n",
    "else:\n",
    "    # Notebook is tracked in the repo\n",
    "    data_dir = curr_dir.replace('/Notebooks', '/Data')\n",
    "\n",
    "#print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PENALTY FUNCTIONS - SOME EXAMPLES\n",
    "\n",
    "# multiplier is a positive number > 0 that determines the slope\n",
    "\n",
    "# Linear Penalty Function\n",
    "def linearPenalty(x, multiplier=1): \n",
    "    return x * multiplier\n",
    "\n",
    "# Flipped/Inverse Linear Penalty Function\n",
    "def invLinearPenalty(x, multiplier=1):\n",
    "    return -x * multiplier\n",
    "\n",
    "# Linear for negative x and zero for positive x\n",
    "def leftLinearPenalty(x, multiplier=1):\n",
    "    if(x < 0): return -x * multiplier\n",
    "    else: return 0\n",
    "    \n",
    "# Linear for positive x and zero for negative x\n",
    "def rightLinearPenalty(x, multiplier=1):\n",
    "    if(x < 0): return 0\n",
    "    else: return x * multiplier\n",
    "\n",
    "# V shape penalty\n",
    "def VPenalty(x, multiplier=1):\n",
    "    if (x < 0): return -x * multiplier\n",
    "    else: return x\n",
    "    \n",
    "# Inverted V shape penalty\n",
    "def invertedVPenalty(x, multiplier=1):\n",
    "    if (x < 0): return x * multiplier\n",
    "    else: return -x * multiplier\n",
    "    \n",
    "# Positive parabola penalty\n",
    "def squaredPenalty(x, multiplier=1):\n",
    "    return (x**2) * multiplier\n",
    "\n",
    "# Inverted parabola penalty\n",
    "def invertedSquaredPenalty(x, multiplier=1):\n",
    "    return -(x**2) * multiplier\n",
    "\n",
    "# Non-linear penalty\n",
    "def nonLinearPenalty(x, multiplier=1):\n",
    "    return x + x**2 + x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "penaltyFunctions = {linearPenalty: \"Linear Penalty\", \n",
    "                    invLinearPenalty: \"Inverse Linear Penalty\",\n",
    "                    leftLinearPenalty: \"Left-Linear Penalty\",\n",
    "                    rightLinearPenalty: \"Right-Linear Penalty\",\n",
    "                    VPenalty: \"V Penalty\",\n",
    "                    invertedVPenalty: \"Inverted-V Penalty\",\n",
    "                    squaredPenalty: \"Squared Penalty\",\n",
    "                    invertedSquaredPenalty: \"Inverted Squared Penalty\",\n",
    "                    nonLinearPenalty: \"Non-Linear Penalty\"\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given a list of error values, plot the penalty function\n",
    "# Error = Actual - Predicted value - This is always along a single dimension because the output is always a single\n",
    "# column in a dataset.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the penalty function for a given list of error values and a given penalty function\n",
    "def penaltyPlot(errorList, penaltyFunction):\n",
    "    # Set up the x-axis\n",
    "    num_points = 200\n",
    "    x = np.linspace(min(errorList), max(errorList), num_points)\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.set(xlabel='Predicted Value - Actual Value')\n",
    "    ax.set(ylabel='Penalty')\n",
    "    ax.axvline(x=0, color='black')\n",
    "    ax.axhline(y=0, color='black')\n",
    "    ax.set(title=penaltyFunctions[penaltyFunction])\n",
    "    ax.plot(x, list(map(penaltyFunction,x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load up the packages to investigate the data\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a column of ones to the first column of a dataframe\n",
    "# and turn it into a matrix\n",
    "def df_addOnes(dataFrame):\n",
    "    vals = dataFrame.values\n",
    "    #add_ones_column = zip(np.ones(len(dataFrame)), vals)\n",
    "    #feature_matrix = np.matrix([val for val in add_ones_column])\n",
    "    feature_matrix = np.c_[np.ones(len(dataFrame)), vals]\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making it easy to calculate the total penalty over the entire dataset\n",
    "def penalty(df_features, df_output, paramater_value_list, penalty_function):\n",
    "    \n",
    "    # df_features is a dataframe of the features (no column of ones added)\n",
    "    # df_output is a dataframe of the output column (target variable)\n",
    "    # parameter_value_list is a list of w0, w1, ..., wn+1 where n is the number of features\n",
    "    #  i.e., the number of columns in df_features.\n",
    "    \n",
    "    # Cost of being wrong calculated over the entire data set\n",
    "    # Will take X and add a first column of 1s to it to enable the matrix multiplication\n",
    "    # Therefore: X is an m x n matrix and theta is a n x 1 matrix\n",
    "    \n",
    "    #### Turn the function inputs into matrices ####\n",
    "    # Get X and y into the right shapes for use in the penalty function\n",
    "    # Add a first column of ones to the feature matrix\n",
    "    # Add a column of 1s to X \n",
    "    feature_matrix = df_addOnes(df_features)\n",
    "    output_matrix = np.matrix(df_output.values)\n",
    "    parameter_matrix = np.matrix(paramater_value_list).T\n",
    "    \n",
    "    #print(feature_matrix.shape, parameter_matrix.shape, output_matrix.shape)\n",
    "    \n",
    "    # Difference between the predicted and the actual value\n",
    "    error = (feature_matrix * parameter_matrix) - output_matrix\n",
    "    #print(error.shape)\n",
    "    \n",
    "    # penaltyPerOutput is an m x 1 matrix where each element is the penalty for\n",
    "    # the input and its associated output for a particular value of W\n",
    "    \n",
    "    # Apply a penalty function to the errors from each row of the dataset\n",
    "    penaltyPerOutput = list(map(penalty_function,error))\n",
    "    \n",
    "    # totalPenalty is the sum of the penalties of each row of the dataset\n",
    "    totalPenalty = np.sum(penaltyPerOutput)\n",
    "    \n",
    "    # The penalty of getting it wrong is 1/2m of the totalPenalty (normalized penalty)\n",
    "    # m is the number of rows in df_features\n",
    "    totalPenaltyNorm = totalPenalty / (2 * len(df_features))\n",
    "    \n",
    "    return totalPenaltyNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement Gradient Descent \n",
    "# **NOTE: ONLY for a squared penalty function**\n",
    "def gradientDescent(df_features, \n",
    "                    df_output, \n",
    "                    init_params_list, \n",
    "                    num_iterations=100, \n",
    "                    learning_rate=0.0001, \n",
    "                    penalty_function=squaredPenalty):\n",
    "    # df_features is a dataframe with the features\n",
    "    # df_ouptut is a dataframe of the output column\n",
    "    # init_params_list is the list of initial W values, e.g., [-1.0, 3.53]\n",
    "    # num_iterations is the number of steps taken by the algorithm as it descends the penalty surface\n",
    "    # learning_rate is the multiplier that determines step size (smaller = smaller step size)\n",
    "    # penalty_function is the penalty function applied to the machine learning problem\n",
    "    # NOTE: The formula for gradient descent we're implementing works only for the squaredPenalty function\n",
    "    \n",
    "    # Get the inputs into matrix form so we can use matrix multiplication (more efficient)\n",
    "    feature_matrix = df_addOnes(df_features)\n",
    "    m = len(feature_matrix) # number of rows of data\n",
    "    output_matrix = np.matrix(df_output.values)\n",
    "    parameter_matrix = np.matrix(init_params_list).T\n",
    "\n",
    "    # This is the initial value of the parameters in matrix form\n",
    "    w = parameter_matrix\n",
    "    \n",
    "    # Set up arrays to capture the running results\n",
    "    # Specify dtype=object because we're putting arrays into an array\n",
    "    #running_w = np.empty(num_iterations, dtype = object)\n",
    "    #running_w = np.array([[ 0.50182941],[-0.07935517]])\n",
    "    running_w = np.array(parameter_matrix)\n",
    "    # don't have to specify dtype for the other arrays because we're putting single values into the array\n",
    "    running_error = np.zeros(num_iterations) \n",
    "    running_normError = np.zeros(num_iterations)\n",
    "    running_penalty = np.zeros(num_iterations)\n",
    "    \n",
    "    # Iterate over the dataset num_iterations times and adjust the values of the parameters each time\n",
    "    for i in range(num_iterations):\n",
    "        #print(w)\n",
    "        for j in range(len(parameter_matrix)):\n",
    "            error = ((feature_matrix * w) - output_matrix).T * np.matrix(feature_matrix[:,j]).T\n",
    "            normError = (learning_rate/m) * error\n",
    "            w[j] = w[j] - normError\n",
    "            #print(w[j])\n",
    "           \n",
    "        # w, error, normError and penalty after each iteration\n",
    "        #running_w[i] = w\n",
    "        running_w = np.append(running_w, w, axis=0)\n",
    "        #print(i)\n",
    "        #print(w)\n",
    "        #print(running_w)\n",
    "        running_error[i] = np.sum((feature_matrix * w) - output_matrix.T)\n",
    "        running_normError[i] = (learning_rate/m) * running_error[i]\n",
    "        running_penalty[i] = penalty_function(running_error[i])\n",
    "    \n",
    "\n",
    "    # w is the value of parameters afer num_iterations\n",
    "    #print(w)\n",
    "\n",
    "    # Get the running_w into the right form\n",
    "    # From https://jasonstitt.com/python-group-iterator-list-function\n",
    "    running_w = list(zip(*[iter(running_w)] * len(parameter_matrix)))\n",
    "    \n",
    "    # error after num_iterations\n",
    "    final_error = np.sum((feature_matrix * w) - output_matrix.T)\n",
    "\n",
    "    # Penalty after num_iterations\n",
    "    final_penalty = penalty_function(final_error)\n",
    "    \n",
    "    return w, final_penalty, running_w, running_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
