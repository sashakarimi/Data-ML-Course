{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Include-3-Shared-Viz-Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the plotting libraries, modules, and styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pyplot module from the matplotlib library\n",
    "from matplotlib import pyplot as plt\n",
    "# Use Jupyter magics to plot inline without needing to call plt.show()\n",
    "# From the documentation (https://stackoverflow.com/questions/43027980/)\n",
    "# \"With backend = 'inline', the output of plotting commands is displayed inline within frontends \n",
    "#   like the Jupyter notebook, directly below the code cell that produced it. \n",
    "#   The resulting plots will then also be stored in the notebook document.\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Seaborn library (by Michael Waskom)\n",
    "import seaborn as sns\n",
    "# Set the visual styles\n",
    "sns.set(context = 'notebook', \n",
    "        style = 'darkgrid',\n",
    "        palette = 'deep', \n",
    "        font = 'sans-serif', \n",
    "        font_scale = 1.3, \n",
    "        color_codes = True, \n",
    "        rc = None\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the matplotlib styles available\n",
    "#print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set the matplotlib style here ####\n",
    "style = 'seaborn-darkgrid'\n",
    "plt.style.use(style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out the style settings\n",
    "#print(\"Here's what the {} style looks like...\".format(style))\n",
    "#fig, axes = plt.subplots(1, 4, figsize=(12, 4))\n",
    "#axes[0].set_xlim(0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotnine for ggplot\n",
    "from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages for computation and data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for number crunching\n",
    "import pandas as pd # for data loading and manipulation\n",
    "import time\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook display settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all columns of a dataframe are displayed\n",
    "# https://stackoverflow.com/questions/47022070/\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that a dataframe column value (e.g., a large text field) is not truncated\n",
    "# https://stackoverflow.com/questions/25351968\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'height': 768, 'scroll': True, 'width': 1024}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure slide scrolling\n",
    "# from hfinger at https://github.com/damianavila/RISE/issues/185\n",
    "#### NOTE: Have to restart notebook server after running it the first time ####\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {'width': 1024, 'height': 768, 'scroll': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of each attribute and the first n values for that attribute in the data set\n",
    "#### SET n HERE ####\n",
    "display_n = 3\n",
    "\n",
    "def get_first_n_vals(dataFrame, n=display_n):\n",
    "    feature_list = list(dataFrame)\n",
    "    first_n = [list(dataFrame[attribute][0:n]) for attribute in feature_list]\n",
    "    return list(enumerate(list(zip(feature_list, first_n))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each feature, how many/what percentage of rows are missing values?\n",
    "# From https://datascience.stackexchange.com/questions/12645/\n",
    "\n",
    "def num_missing_values_per_feature(dataFrame, display='percentage'):\n",
    "    if display == 'count':\n",
    "        return dataFrame.isnull().sum(axis=0)\n",
    "    else:\n",
    "        return dataFrame.isnull().sum(axis=0)/len(dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row, how many/what percentage of rows are missing values?\n",
    "# From https://datascience.stackexchange.com/questions/12645/\n",
    "\n",
    "def num_missing_values_per_row(dataFrame, display='percentage'):\n",
    "    if display == 'count':\n",
    "        return dataFrame.isnull().sum(axis=1)\n",
    "    else:\n",
    "        return dataFrame.isnull().sum(axis=1)/len(dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Display Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique values of the categorical attributes/features\n",
    "def get_cat_values(dataFrame, cat_feature_set):\n",
    "    # dataFrame is the dataset in pandas dataframe format\n",
    "    # cat_feature_set is a list of categorical feature names\n",
    "    \n",
    "    return list(zip(cat_feature_set, \\\n",
    "                    [dataFrame[cat_feature].unique() for cat_feature in cat_feature_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot - use for categorical features\n",
    "# Show how a categorical feature's values are distributed across the possible values it can take\n",
    "def cat_value_dist(dataFrame, feature, display='percentage', orient='vert'):\n",
    "    # display can be 'percentage' (default) or 'count'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    # The unique values the feature takes\n",
    "    feat_values = dataFrame[feature].unique()\n",
    "    \n",
    "    # To make the plot vertical, use x=feature in the 'count' display and (feat_values, y) in the 'percentage' display\n",
    "    # To make the plot horizontal, use y=feature in the 'count' display and (y, feat_values) in the 'percentage' display\n",
    "    if display == 'count':\n",
    "        if orient == 'vert': \n",
    "            ax = sns.countplot(x=feature, data=dataFrame)\n",
    "        else:\n",
    "            # horiz orientation \n",
    "            ax = sns.countplot(y=feature, data=dataFrame)\n",
    "    elif display == 'percentage':\n",
    "        y = [len([val for val in dataFrame[feature] if val == x_val])/len(dataFrame[feature]) * 100 for x_val in feat_values]\n",
    "        if orient == 'vert': \n",
    "            ax = sns.barplot(feat_values, y)\n",
    "        else:\n",
    "            # horiz orientation\n",
    "            ax = sns.barplot(y, feat_values)\n",
    "    \n",
    "    # If the number of distinct values is greater than n, rotate the labels\n",
    "    n = 3\n",
    "    if len(feat_values) > n:\n",
    "        plt.xticks(rotation=90)\n",
    "    \n",
    "    if orient == 'vert':\n",
    "        plt.ylabel(display)\n",
    "        plt.title(feature)\n",
    "    else:\n",
    "        plt.ylabel(feature)\n",
    "        plt.title(display)\n",
    "    \n",
    "    # If %matplotlib inline is invoked, we don't need to return plt.show()\n",
    "    #return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Relationship Between Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contingency table to track the relationship between any two categorical variables\n",
    "def contingency_table(dataFrame, row_feat, col_feat):\n",
    "    # dataFrame is the complete dataset\n",
    "    # row_feat is the feature whose values are displayed as rows\n",
    "    # col_feat is the feature whose values are displayed across columns\n",
    "    ct = pd.crosstab(index=dataFrame[row_feat], \n",
    "                     columns=dataFrame[col_feat]\n",
    "                    )\n",
    "\n",
    "    return ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a contingency table as a stacked bar chart\n",
    "def plot_contingency_table(dataFrame, row_feat, col_feat, stacked=True):\n",
    "    ct = contingency_table(dataFrame, row_feat, col_feat)\n",
    "    # For horizontal chart use kind='barh'\n",
    "    # For vertical chart use kind='bar'\n",
    "    ct.plot(kind=\"barh\", \n",
    "            figsize=(10,8), \n",
    "            stacked=stacked\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to visualize the relationship between 2 categorical features\n",
    "# Requires the plotnine package\n",
    "\n",
    "def cat_2_bars(dataFrame, x_feat, y_feat):\n",
    "    disp = (ggplot(dataFrame, aes(x=x_feat, fill=y_feat)) \\\n",
    "            + geom_bar(position='fill') \\\n",
    "            + ylab('Percentage') \\\n",
    "            + theme(axis_text_x=element_text(rotation=90, hjust=1)))\n",
    "    \n",
    "    return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between 3 categorical variables\n",
    "# Requires the plotnine package\n",
    "\n",
    "def cat_3_bars(dataFrame, x_feat, y_feat, z_feat):\n",
    "    disp = (ggplot(dataFrame, aes(x=x_feat, fill=y_feat)) \\\n",
    "            + geom_bar(position='fill') \\\n",
    "            + facet_wrap('~' + z_feat) \\\n",
    "            + ylab('Percentage') \\\n",
    "            + theme(axis_text_x=element_text(rotation=90, hjust=1))\n",
    "           )\n",
    "    \n",
    "    return disp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skyline of a single numerical feature\n",
    "def num_skyline(dataFrame, num_feature_name, x_axis_label, y_axis_label='Count'):\n",
    "    feat_vals = dataFrame[num_feature_name]\n",
    "    feat_vals_sorted = np.array(feat_vals.sort_values())\n",
    "    feat_vals_freq = [len(list(group)) for key, group in groupby(feat_vals_sorted)]\n",
    "    feat_labels = np.unique(feat_vals_sorted)\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    height = feat_vals_freq\n",
    "    bars = feat_labels\n",
    "    y_pos = np.arange(len(bars))\n",
    " \n",
    "    # Create bars\n",
    "    plt.bar(y_pos, height)\n",
    "\n",
    "    # Add title and axis names\n",
    "    plt.xlabel(x_axis_label)\n",
    "    plt.ylabel(y_axis_label)\n",
    "\n",
    " \n",
    "    # Create names on the x-axis\n",
    "    plt.xticks(y_pos, feat_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot with customized bin widths\n",
    "def num_skyline_hist(dataFrame, \n",
    "                     num_feature_name,\n",
    "                     bin_width, \n",
    "                     bin_min, \n",
    "                     bin_max, \n",
    "                     x_axis_label, \n",
    "                     y_axis_label='Count'):\n",
    "    \n",
    "    # bin_width is the width of each bin in the histogram\n",
    "    # bin_min is the lowest value of the feature\n",
    "    # bin_max is the highest value of the feature\n",
    "    \n",
    "    feat_vals = dataFrame[num_feature_name]\n",
    "    feat_vals_sorted = np.array(feat_vals.sort_values())\n",
    "    feat_vals_freq = [len(list(group)) for key, group in groupby(feat_vals_sorted)]\n",
    "    #feat_labels = np.unique(feat_vals_sorted)\n",
    "    \n",
    "    bin_freqs = []\n",
    "    bin_labels = []\n",
    "    while bin_min < bin_max:\n",
    "        bin_next = bin_min + bin_width\n",
    "        #print(bin_next)\n",
    "        bin_label = ' '.join([str(bin_min), 'to', str(bin_next)])\n",
    "        bin_labels.append(bin_label)\n",
    "        vals_in_bin = len([item for item in feat_vals_sorted if (item >= bin_min) & (item < bin_next)])\n",
    "        #print(vals_in_bin)\n",
    "        bin_freqs.append(vals_in_bin)\n",
    "        bin_min = bin_next\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    height = bin_freqs\n",
    "    bars = bin_labels\n",
    "    y_pos = np.arange(len(bars))\n",
    " \n",
    "    # Create bars\n",
    "    plt.bar(y_pos, height)\n",
    "\n",
    "    # Add title and axis names\n",
    "    plt.xlabel(x_axis_label)\n",
    "    plt.ylabel(y_axis_label)\n",
    "\n",
    " \n",
    "    # Create names on the x-axis\n",
    "    plt.xticks(y_pos, bars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of a single numerical feature as a histogram \n",
    "# or a probability distribution (kde)\n",
    "def num_hist(dataFrame, num_feature_name, kde=False):\n",
    "    # dataFrame is the entire dataset\n",
    "    # num_feature_name is the name of a single numerical feature, e.g., 'numerical_feature'\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    sns.distplot(dataFrame[num_feature_name], bins=7, kde=kde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOTE: Boxplot of a single numerical feature ####\n",
    "# Use num_boxplot_mult(dataFrame, ['num_feature_name'])\n",
    "# num_boxplot_mult is defined below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series for a single numerical feature\n",
    "def time_series_plot(dataFrame, time_feature_name, num_feature_name):\n",
    "    # dataFrame is the entire dataset\n",
    "    # time_feature_name is the name of a the time feature, e.g., 'PUBLISHED_DATE'\n",
    "    # num_feature_name is the name of the numerical feature that evolves in time, e.g., 'COUNT_IVR'\n",
    "    \n",
    "    # First sort the dataframe in ascending order of the time_feature_name\n",
    "    df_sorted = dataFrame.sort_values(by=[time_feature_name])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    x = df_sorted[time_feature_name]\n",
    "    y = df_sorted[num_feature_name]\n",
    "    plt.plot(x,y, marker='o')\n",
    "    #ax.tick_params(labelbottom='off') # turn off the x axis tick labels\n",
    "    plt.xticks(rotation=90) # rotate the x axis tick labels\n",
    "    ax.set_xlabel(time_feature_name)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series evolution of a list of numerical features\n",
    "def time_series_mult_plot(dataFrame, time_feature_name, num_feature_list, highlighted_feature=''):\n",
    "    # dataFrame is the entire dataset\n",
    "    # time_feature_name is the name of a the time feature, e.g., 'PUBLISHED_DATE'\n",
    "    # num_feature_list contains the names of the numerical features that evolve in time, \n",
    "    # e.g., ['COUNT_IVR', ..., 'Avg_Dwell_Time'] or quality_feats\n",
    "    # highlighted_feature is the feature in the num_feature_list to highlight in the plot\n",
    "    \n",
    "    # First sort the dataframe in ascending order of the time_feature_name\n",
    "    df_sorted = dataFrame.sort_values(by=[time_feature_name])\n",
    "    \n",
    "    if highlighted_feature != '':\n",
    "        # Create the abriged list of numerical features\n",
    "        abbr_feature_list = [x for x in num_feature_list if x != highlighted_feature]\n",
    "    \n",
    "    # set up the plot\n",
    "    fig, ax = plt.subplots(figsize=(14,10))\n",
    "    x = df_sorted[time_feature_name]\n",
    "    if highlighted_feature != '':\n",
    "        y = df_sorted[abbr_feature_list]\n",
    "    else:\n",
    "        y = df_sorted[num_feature_list]\n",
    "    plt.plot(x,y)\n",
    "    \n",
    "    #ax.tick_params(labelbottom='off') # no x axis tick labels\n",
    "    plt.xticks(rotation=90) # rotate the x axis tick labels\n",
    "    ax.set_xlabel(time_feature_name)\n",
    "\n",
    "    # Now re-plot the highlighted feature - bigger with distinct color\n",
    "    if highlighted_feature != '':\n",
    "        plt.plot(x, df_sorted[highlighted_feature], marker='o', color='purple', linewidth=3, alpha=0.7)\n",
    "        plt.legend(abbr_feature_list + [highlighted_feature])\n",
    "    else:\n",
    "        plt.legend(num_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series plots for a list of numerical features displayed side by side\n",
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Relationships Between Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple contour plot of the KDE for any two numerical features\n",
    "def kde_contour(dataFrame, num_feature_1, num_feature_2):\n",
    "    # dataFrame is the entire dataset\n",
    "    # num_feature_1 and 2 are individual numerical feature names, e.g., 'numerical_feature'\n",
    "    sns.kdeplot(dataFrame[num_feature_1], dataFrame[num_feature_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE contour + distribution for any two numerical features\n",
    "def kde_contour_dist(dataFrame, num_feature_1, num_feature_2, kind='kde'):\n",
    "    # dataFrame is the entire dataset\n",
    "    # num_feature_1 and 2 are individual numerical feature names, e.g., 'numerical_feature'\n",
    "    # kind = 'kde' or 'hex'\n",
    "    with sns.axes_style('white'):\n",
    "        sns.jointplot(x=dataFrame[num_feature_1], y=dataFrame[num_feature_2], kind=kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple histograms\n",
    "def num_hist_mult(dataFrame, num_feature_list):\n",
    "    # dataFrame is the entire dataset\n",
    "    # num_feature_list is a list of numerical features, e.g., ['num_feat1', ..., 'num_feat_N']\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    for num_feature in num_feature_list:\n",
    "        plt.hist(dataFrame[num_feature], normed=True, alpha=0.5, label=num_feature)\n",
    "        \n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution density curves overlayed\n",
    "# Distributions of a set of numerical features\n",
    "def num_kde_mult(dataFrame, num_feature_list):\n",
    "    # dataFrame is the entire dataset\n",
    "    # num_feature_list is a list of numerical features, e.g., ['num_feat1', ..., 'num_feat_N']\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    for num_feature in num_feature_list:\n",
    "        sns.kdeplot(dataFrame[num_feature], label=num_feature)\n",
    "        \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both histograms and density curves overlayed\n",
    "# Distributions of a set of numerical features\n",
    "def num_hist_kde_mult(dataFrame, num_feature_list):\n",
    "    # dataFrame is the entire dataset\n",
    "    # num_feature_list is a list of numerical features, e.g., ['num_feat1', ..., 'num_feat_N']\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    for num_feature in num_feature_list:\n",
    "        sns.distplot(dataFrame[num_feature], label=num_feature)\n",
    "        \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots for a set of numerical features\n",
    "# The swarmplot shows the data points jittered for better visibility\n",
    "# Another option instead of the jitter is to use a violinplot (for large datasets)\n",
    "def num_boxplot_mult(dataFrame, num_feature_list):\n",
    "    # dataFrame is the entire dataset\n",
    "    # num_feature_list is a list of numerical features, e.g., ['num_feat1', ..., 'num_feat_N']\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    ax = sns.boxplot(data=dataFrame[num_feature_list], palette='Set2')\n",
    "    ax = sns.swarmplot(data=dataFrame[num_feature_list], color='grey')\n",
    "    \n",
    "     # If the number of distinct values is greater than n, rotate the labels\n",
    "    n = 3\n",
    "    if len(num_feature_list) > n:\n",
    "        plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Table -- Display the relationship between \n",
    "# Correlation Density Plot\n",
    "def num_corr_table(dataFrame, num_feature_list):\n",
    "    # dataFrame is the entire dataset\n",
    "    # num_feature_list is a list of numerical features, e.g., ['num_feat1', ..., 'num_feat_N']\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    cm = dataFrame[num_feature_list].corr()\n",
    "    sns.set(font_scale=1)\n",
    "    #### NOTE: fmt directive controls number of decimal points displayed in the correlation value. ####\n",
    "    hm = sns.heatmap(cm,\n",
    "                     cbar=True,\n",
    "                     annot=True,\n",
    "                     square=False,\n",
    "                     fmt='.2f',\n",
    "                     annot_kws={'size':14},\n",
    "                     yticklabels=num_feature_list,\n",
    "                     xticklabels=num_feature_list\n",
    "                    )\n",
    "\n",
    "    plt.title('Correlation Heat Map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bubble chart showing the relationship between any three numerical features\n",
    "def bubble_chart(dataFrame, x_feature, y_feature, bubble_size_feature):\n",
    "    # dataFrame is the entire dataset\n",
    "    # x_feature and y_feature are numerical features on the x and y axis respectively\n",
    "    # bubble_size_feature is represented by the size of the bubble\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    x = dataFrame[x_feature]\n",
    "    y = dataFrame[y_feature]\n",
    "    if bubble_size_feature == 'UNIQUE_USERS':\n",
    "        bubble_size = dataFrame[bubble_size_feature]/100. # scale bubble size\n",
    "    else:\n",
    "        bubble_size = dataFrame[bubble_size_feature] # No need to scale bubble size\n",
    "    plt.scatter(x, y, s=bubble_size*2000, c=x, cmap=\"Blues\", alpha=0.4, edgecolors=\"orange\", linewidth=2)\n",
    "    plt.xlabel(x_feature)\n",
    "    plt.ylabel(y_feature)\n",
    "    plt.title(\"Bubble Size = \" + bubble_size_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Relationships Between Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at how a single numerical feature varies across a single categorical feature\n",
    "# Box plot display\n",
    "def box_plot(dataFrame, cat_feature, num_feature, orient='h'):\n",
    "    # dataFrame is the entire dataset\n",
    "    # cat_feature is the name of a single categorical feature \n",
    "    # num_feature is the name of a single numerical feature\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    if orient == 'v':\n",
    "        ax = sns.boxplot(x=dataFrame[cat_feature], y=dataFrame[num_feature], palette=\"Set2\")\n",
    "    elif orient == 'h':\n",
    "        ax = sns.boxplot(x=dataFrame[num_feature], y=dataFrame[cat_feature], palette=\"Set2\")\n",
    "    \n",
    "    if len(dataFrame[cat_feature].unique()) > 3:\n",
    "        plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at how a single numerical feature varies across a single categorical feature\n",
    "# Jitter plot display\n",
    "def jitter_plot(dataFrame, cat_feature, num_feature, orient='h'):\n",
    "    # dataFrame is the entire dataset\n",
    "    # cat_feature is the name of a single categorical feature \n",
    "    # num_feature is the name of a single numerical feature\n",
    "    fig, ax = plt.subplots(figsize=(10,6))\n",
    "    if orient == 'v':\n",
    "        ax = sns.stripplot(x=cat_feature, y=num_feature, data=dataFrame, jitter=0.1)\n",
    "    elif orient == 'h':\n",
    "        ax = sns.stripplot(y=cat_feature, x=num_feature, data=dataFrame, jitter=0.1)\n",
    "    \n",
    "    if len(dataFrame[cat_feature].unique()) > 3:\n",
    "        plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between a set of numerical features and \n",
    "# a given categorical feature\n",
    "# Scatter plot format\n",
    "\n",
    "def num_cat_scatter(dataFrame, num_feats_list, cat_feat_name):\n",
    "    # dataFrame is the entire dataset\n",
    "    # num_feats_list is the list of numerical features, e.g., doc_feats\n",
    "    # cat_feat_name is the name of the single categorical feature, e.g., 'AUTHOR_NAME'\n",
    "    \n",
    "    # Create the combined dataframe\n",
    "    feat_list = num_feats_list + [cat_feat_name]\n",
    "    \n",
    "    # Create the pairplot\n",
    "    sns.pairplot(dataFrame[feat_list], kind='scatter', hue=cat_feat_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between a set of numerical features and \n",
    "# a given categorical feature\n",
    "# Regression plot format\n",
    "\n",
    "def num_cat_regress(dataFrame, num_feats_list, cat_feat_name):\n",
    "    # dataFrame is the entire dataset\n",
    "    # num_feats_list is the list of numerical features, e.g., doc_feats\n",
    "    # cat_feat_name is the name of the single categorical feature, e.g., 'AUTHOR_NAME'\n",
    "    \n",
    "    # Create the combined dataframe\n",
    "    feat_list = num_feats_list + [cat_feat_name]\n",
    "    \n",
    "    # Create the pairplot\n",
    "    sns.pairplot(dataFrame[feat_list], kind='reg', hue=cat_feat_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of two numerical features grouped by a categorical feature\n",
    "def scatter_plot(dataFrame, num_feat_x, num_feat_y, cat_feat):\n",
    "    \n",
    "    # See https://xkcd.com/color/rgb/ for xkcd named colors\n",
    "    xkcd_colors = [\"blue\", \"hot pink\", \"violet\", \"olive\", \"lime green\", \"lemon yellow\", \"goldenrod\", \"dark orange\"]\n",
    "    \n",
    "    # Use the 'hue' argument to provide a factor variable\n",
    "    sns.lmplot(x=num_feat_x, \n",
    "               y=num_feat_y, \n",
    "               data=dataFrame, \n",
    "               fit_reg=False, \n",
    "               hue=cat_feat,\n",
    "               size=8, \n",
    "               aspect=1.5,\n",
    "               legend_out=True, \n",
    "               palette=sns.xkcd_palette(xkcd_colors), \n",
    "               scatter_kws={'s':200}\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot that accommodates the classification of the scatter dots into a large number of items\n",
    "# Use when the number of the items in a group is > 5\n",
    "def scatter_plot_large(dataFrame, num_feat_x, num_feat_y, cat_feat, slice_num, slicing_feat='AUTHOR_NAME'):\n",
    "    # dataFrame is the entire dataset\n",
    "    # num_feat_x is the numerical feature for the x axis\n",
    "    # num_feat_y is the numerical feature for the y axis\n",
    "    # cat_feature is the categorical feature by which the dots are grouped\n",
    "    # slice_num is the index number of the slice for which we want to create the scatter plot\n",
    "    ## For example, slice_list[0] might be CIOLC, slice_list[1] might be ALC, etc.\n",
    "    # slicing_feat is the slicing to be applied to the entire dataset; for example, \n",
    "    ## 'AUTHOR_NAME' slices the data set by creating a data frame for each AUTHOR_NAME which \n",
    "    ## in our case designates the name of a functional practice (e.g., CIO, Applications, Infrastructure, ...)\n",
    "    \n",
    "    # The names of the various items by which to slice the dataFrame\n",
    "    ## Typically, these slices will be slices by the leadership councils (slicing_feat='AUTHOR_NAME')\n",
    "    slice_list = np.unique(dataFrame[slicing_feat].values)\n",
    "\n",
    "    # Rows of data for a given item in the slice_list\n",
    "    df_slice = dataFrame[dataFrame[slicing_feat] == slice_list[slice_num]]\n",
    "    \n",
    "    # Get the title of the plot\n",
    "    plt_title = np.unique(df_slice[slicing_feat].values)[0]\n",
    "\n",
    "    # The unique items in the cat_feat for the given df_slice\n",
    "    cat_titles = df_slice[cat_feat].values\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(18,10))\n",
    "    # basic plot\n",
    "    p1=sns.regplot(data=df_slice, \n",
    "                   x=df_slice[num_feat_x], \n",
    "                   y=df_slice[num_feat_y], \n",
    "                   fit_reg=False, \n",
    "                   marker=\"o\", \n",
    "                   color=\"blue\",\n",
    "                   scatter_kws={'s':100}, \n",
    "                   ax=ax\n",
    "                  )\n",
    "\n",
    "    # add annotations one by one with a loop\n",
    "    for line in range(0,df_slice.shape[0]):\n",
    "        p1.text(df_slice[num_feat_x].values[line]+0.4, \n",
    "                df_slice[num_feat_y].values[line]+0.2, \n",
    "                cat_titles[line], \n",
    "                horizontalalignment='left', \n",
    "                size='medium', \n",
    "                color='black', \n",
    "                weight='normal')\n",
    "\n",
    "    ax.set_title(plt_title)\n",
    "    ax.set_xlim(0, 60);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at how a single numerical feature varies across two categorical features\n",
    "# Grouped boxplot display\n",
    "def grouped_boxplot(dataFrame, x_cat_feature, y_num_feature, z_cat_feature):\n",
    "    fig, ax = plt.subplots(figsize=(14,8))\n",
    "    sns.boxplot(x=x_cat_feature, \n",
    "                y=y_num_feature, \n",
    "                hue=z_cat_feature, \n",
    "                data=dataFrame, \n",
    "                palette=\"Set3\"\n",
    "               )\n",
    "    if len(dataFrame[x_cat_feature].unique()) > 3:\n",
    "        plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset for Use in ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This is a single longish function that creates inputs for any ML model ####\n",
    "#### For unsupervised models, the entire dataset is returned ####\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import math\n",
    "\n",
    "def create_model_input(df_dataset, \n",
    "                       target_feature,\n",
    "                       target_feature_type, \n",
    "                       categorical_features_list, \n",
    "                       numerical_features_list, \n",
    "                       scaler='Standard'\n",
    "                      ):\n",
    "    \n",
    "    # df_dataset is a complete pre-processed input dataset, e.g., df_ig\n",
    "    # target_feature is the feature that is the target for the model\n",
    "    #### NOTE: if target_feature is '', then the entire dataset is returned after been one-hot encoded and scaled ####\n",
    "    # target_type is 'categorical' or 'numerical' or '' (when there is no target specified)\n",
    "    # categorical_features_list is the list of categorical features used by the model \n",
    "    #  (will include the target feature if the target feature is categorical)\n",
    "    # numerical_features_list is the list of numerical features used by the model\n",
    "    #  (will include the target feature if the target feature is numerical)\n",
    "    # scaler can be 'Standard' (default) or 'MinMax'\n",
    "    \n",
    "    #### Step 1: Decide how to split the dataset into train, validate, and test datasets ####\n",
    "    # VAL_PCT_SPLIT can be set to 0.0 if needed\n",
    "    TRAIN_PCT_SPLIT = 0.8\n",
    "    VAL_PCT_SPLIT = 0.0\n",
    "    TEST_PCT_SPLIT = 0.2\n",
    "    \n",
    "    #### Step 2: Separate the target feature from the other features ####\n",
    "    if target_feature != '':\n",
    "        categorical_features = [x for x in categorical_features_list if x != target_feature]\n",
    "        numerical_features = [x for x in numerical_features_list if x != target_feature]\n",
    "    else:\n",
    "        categorical_features = categorical_features_list\n",
    "        numerical_features = numerical_features_list\n",
    "    \n",
    "    #### Step 3: Create a dataset with the requisite features for the model from the full dataset ####\n",
    "    if target_feature != '':\n",
    "        df_model = df_dataset[categorical_features + numerical_features + [target_feature]]\n",
    "    else:\n",
    "        df_model = df_dataset[categorical_features + numerical_features]\n",
    "    \n",
    "    #### Step 4: One-hot-encode the categorical features ####\n",
    "    df_model = pd.get_dummies(df_model, columns=categorical_features)\n",
    "    \n",
    "    #### Step 5: Label encode the target feature if it's a categorical feature ####\n",
    "    if target_feature_type == 'categorical':\n",
    "        le = LabelEncoder()\n",
    "        df_model[target_feature] = le.fit_transform(df_model[target_feature])\n",
    "        \n",
    "    #### df_model now contains all the features and the target we need\n",
    "    ####  in addition, df_model has its categorical features one-hot-encoded and \n",
    "    ####  its label/target encoded if needed\n",
    "    \n",
    "    #### Step 6: Shuffle the dataset and split it into train, val, and test ####\n",
    "    # Shuffle the one-hot-encoded and label-encoded dataset\n",
    "    df_shuff = shuffle(df_model, random_state=42) # set seed for replicability\n",
    "    \n",
    "    (num_rows, num_cols) = df_shuff.shape\n",
    "    \n",
    "    num_train = math.floor(TRAIN_PCT_SPLIT * num_rows)\n",
    "    num_val = math.floor(VAL_PCT_SPLIT * num_rows)\n",
    "    # num_test consists of the remaning rows of the dataset\n",
    "    num_test = num_rows - (num_train + num_val)\n",
    "    \n",
    "    # Train, val, and test dataframes\n",
    "    df_train = df_shuff.iloc[0:num_train]\n",
    "    df_val = df_shuff.iloc[num_train:num_train+num_val]\n",
    "    df_test = df_shuff.iloc[num_train+num_val: ]\n",
    "    \n",
    "    # df_val_test combines df_val and df_test in case we don't need them separately\n",
    "    # . e.g., when using k-fold cross validation with a scikit classifier\n",
    "    # Typically used when the dataset is small\n",
    "    df_val_test = pd.concat([df_val, df_test], axis=0)\n",
    "    \n",
    "    # Use df_train_val to (re)train the optimal model once the optimal model \n",
    "    #  has been determined using grid search\n",
    "    df_train_val = pd.concat([df_train, df_val], axis=0)\n",
    "    \n",
    "    # And finally, this is the entire dataset (for unsupervised learning, e.g., clustering analysis)\n",
    "    df_full = pd.concat([df_train_val, df_test], axis=0)\n",
    "     \n",
    "    #### Step 8: Scale the numerical features OVER THE TRAINING DATASET ONLY ####\n",
    "    if scaler == 'Standard':\n",
    "        sc = StandardScaler()\n",
    "    elif scaler == 'MinMax':\n",
    "        sc = MinMaxScaler()\n",
    "    else:\n",
    "        sc = StandardScaler() # use StandardScaler as the default scaler\n",
    "    \n",
    "    #### NOTE: a copy is made to aviod the pandas SettingWithCopying warning ####\n",
    "    #### See https://www.dataquest.io/blog/settingwithcopywarning/ ####\n",
    "    if target_feature == '':\n",
    "        # Scale the entire dataset's numerical features\n",
    "        df_full_scaled = df_full.copy()\n",
    "        df_full_scaled[numerical_features] = sc.fit_transform(df_full[numerical_features])\n",
    "    else:\n",
    "        df_full_scaled = df_full\n",
    "    \n",
    "    # Scale just the training dataset and use these scaler values to scale the val and test datasets\n",
    "    df_train_scaled = df_train.copy()\n",
    "    df_train_scaled[numerical_features] = sc.fit_transform(df_train[numerical_features])\n",
    "\n",
    "    \n",
    "    #### Step 9: Scale the numerical features of the other datasets using the scaler values\n",
    "    ####  of the training dataset ####\n",
    "    #### NOTE: a copy is made to aviod the pandas SettingWithCopying warning ####\n",
    "    #### See https://www.dataquest.io/blog/settingwithcopywarning/ ####\n",
    "    \n",
    "    # Check to make sure that the validation slice % is not 0\n",
    "    if len(df_val) > 0:\n",
    "        df_val_scaled = df_val.copy()\n",
    "        df_val_scaled[numerical_features] = sc.transform(df_val[numerical_features])\n",
    "    else:\n",
    "        df_val_scaled = df_val\n",
    "    \n",
    "    df_test_scaled = df_test.copy()\n",
    "    df_test_scaled[numerical_features] = sc.transform(df_test[numerical_features])\n",
    "    \n",
    "    df_val_test_scaled = df_val_test.copy()\n",
    "    df_val_test_scaled[numerical_features] = sc.transform(df_val_test[numerical_features])\n",
    "    \n",
    "    df_train_val_scaled = df_train_val.copy()\n",
    "    df_train_val_scaled[numerical_features] = sc.transform(df_train_val[numerical_features])\n",
    "    \n",
    "    #### Step 10: Get the targets for SciKit Learn models as a (num, ) shape array of reals ####\n",
    "    #### there are no y values for the full dataset becuause there is no target ####\n",
    "    if target_feature != '':\n",
    "        y_train = df_train_scaled[target_feature].values.astype('float32')\n",
    "        y_val = df_val_scaled[target_feature].values.astype('float32')\n",
    "        y_test = df_test_scaled[target_feature].values.astype('float32')\n",
    "        y_val_test = df_val_test_scaled[target_feature].values.astype('float32')\n",
    "        y_train_val = df_train_val_scaled[target_feature].values.astype('float32')\n",
    "    else:\n",
    "        y_train = []\n",
    "        y_val = []\n",
    "        y_test = []\n",
    "        y_val_test = []\n",
    "        y_train_val = []\n",
    "    \n",
    "    #### Step 11: Create the input and target arrays ####\n",
    "    # Get the feature array as it currently exists for the df_prepped_dataset\n",
    "    #### NOTE: The feature names may have changed when the categorical features\n",
    "    #### are one-hot-encoded\n",
    "    # So features are now all column names EXCEPT for the Target\n",
    "    features_list = list(df_train_scaled)\n",
    "    if target_feature != '':\n",
    "        features_list.remove(target_feature)\n",
    "    \n",
    "    X_train = df_train_scaled[features_list].values\n",
    "    X_val = df_val_scaled[features_list].values\n",
    "    X_test = df_test_scaled[features_list].values\n",
    "    X_val_test = df_val_test_scaled[features_list].values\n",
    "    X_train_val = df_train_val_scaled[features_list].values\n",
    "    if target_feature == '':\n",
    "        X_full = df_full_scaled[features_list].values\n",
    "    else:\n",
    "        X_full = []\n",
    "    \n",
    "    \n",
    "    #### OUTPUTS ####\n",
    "    dict_model_inputs = {'X_train': X_train, \n",
    "                         'X_val': X_val, \n",
    "                         'X_test': X_test, \n",
    "                         'X_val_test': X_val_test, \n",
    "                         'X_train_val': X_train_val,\n",
    "                         'X_full': X_full, \n",
    "                         'y_train': y_train, \n",
    "                         'y_val': y_val, \n",
    "                         'y_test': y_test, \n",
    "                         'y_val_test': y_val_test, \n",
    "                         'y_train_val': y_train_val\n",
    "                        }\n",
    "    \n",
    "    return dict_model_inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
